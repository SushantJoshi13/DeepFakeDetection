{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_face(face):\n",
    "    # Example: Convert to grayscale\n",
    "    gray_face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Example: Resize to a standard size (adjust as needed)\n",
    "    resized_face = cv2.resize(gray_face, (224, 224))\n",
    "\n",
    "    return resized_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_and_faces(video_path, output_dir,reduced_output_dir, video_count, scale_factor=1.5, every_nth_frame=25):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    frame_count = 0\n",
    "    num_faces = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detector(gray_frame)\n",
    "\n",
    "        # Handle no faces detected\n",
    "        if not faces:\n",
    "            continue\n",
    "\n",
    "        num_faces = len(faces)  # Update face count after filtering\n",
    "\n",
    "        # Create separate folder for each face if multiple faces detected\n",
    "        if num_faces > 1:\n",
    "            face_id = 0\n",
    "            for face in faces:\n",
    "                x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "\n",
    "                # Increase the size of the rectangle by a scale factor\n",
    "                x -= int(w * (scale_factor - 1) / 2)\n",
    "                y -= int(h * (scale_factor - 1) / 2)\n",
    "                w = int(w * scale_factor)\n",
    "                h = int(h * scale_factor)\n",
    "\n",
    "                # Ensure the new rectangle coordinates are within the frame boundaries\n",
    "                x = max(0, x)\n",
    "                y = max(0, y)\n",
    "                w = min(frame.shape[1] - x, w)\n",
    "                h = min(frame.shape[0] - y, h)\n",
    "\n",
    "                cropped_face = frame[y:y + h, x:x + w]\n",
    "                processed_face = preprocess_face(cropped_face)\n",
    "\n",
    "                face_output_dir = os.path.join(output_dir, f\"face_{face_id}\")\n",
    "                if not os.path.exists(face_output_dir):\n",
    "                    os.makedirs(face_output_dir)\n",
    "\n",
    "                save_path = os.path.join(face_output_dir, f\"frame_{frame_count}_{video_count}.jpg\")\n",
    "                cv2.imwrite(save_path, processed_face)\n",
    "\n",
    "                face_id += 1\n",
    "\n",
    "        # Single face detected: Save all frames to main folder, and every nth frame to reduced folder\n",
    "        else:\n",
    "            face = faces[0]\n",
    "            x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "\n",
    "            # Increase the size of the rectangle by a scale factor\n",
    "            x -= int(w * (scale_factor - 1) / 2)\n",
    "            y -= int(h * (scale_factor - 1) / 2)\n",
    "            w = int(w * scale_factor)\n",
    "            h = int(h * scale_factor)\n",
    "\n",
    "            # Ensure the new rectangle coordinates are within the frame boundaries\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w = min(frame.shape[1] - x, w)\n",
    "            h = min(frame.shape[0] - y, h)\n",
    "\n",
    "            cropped_face = frame[y:y + h, x:x + w]\n",
    "            processed_face = preprocess_face(cropped_face)\n",
    "\n",
    "            save_path = os.path.join(output_dir, f\"frame_{frame_count}_{video_count}.jpg\")\n",
    "            cv2.imwrite(save_path, processed_face)\n",
    "\n",
    "            # Extract every nth frame for reduced dataset\n",
    "            if frame_count % every_nth_frame == 0:\n",
    "                if not os.path.exists(reduced_output_dir):\n",
    "                    os.makedirs(reduced_output_dir)\n",
    "\n",
    "                reduced_save_path = os.path.join(reduced_output_dir, f\"frame_{frame_count}_{video_count}.jpg\")\n",
    "                cv2.imwrite(reduced_save_path, processed_face)\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_video(filepath):\n",
    "  video_extensions = (\".mp4\", \".avi\", \".mkv\", \".wmv\", \".flv\", \".mov\")\n",
    "  _, extension = os.path.splitext(filepath)\n",
    "  return extension.lower() in video_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "23__walk_down_hall_angry.mp4\n",
      "23__walk_down_hall_angry.mp4\n",
      "24__exit_phone_room.mp4\n",
      "24__exit_phone_room.mp4\n",
      "24__kitchen_pan.mp4\n",
      "24__kitchen_pan.mp4\n",
      "24__kitchen_still.mp4\n",
      "24__kitchen_still.mp4\n",
      "24__outside_talking_pan_laughing.mp4\n",
      "24__outside_talking_pan_laughing.mp4\n",
      "24__outside_talking_still_laughing.mp4\n",
      "24__outside_talking_still_laughing.mp4\n",
      "24__podium_speech_happy.mp4\n",
      "24__podium_speech_happy.mp4\n",
      "24__secret_conversation.mp4\n",
      "24__secret_conversation.mp4\n",
      "24__talking_against_wall.mp4\n",
      "24__talking_against_wall.mp4\n",
      "24__talking_angry_couch.mp4\n",
      "24__talking_angry_couch.mp4\n",
      "24__walking_down_street_outside_angry.mp4\n",
      "24__walking_down_street_outside_angry.mp4\n",
      "24__walking_outside_cafe_disgusted.mp4\n",
      "24__walking_outside_cafe_disgusted.mp4\n",
      "24__walk_down_hall_angry.mp4\n",
      "24__walk_down_hall_angry.mp4\n",
      "25__exit_phone_room.mp4\n",
      "25__exit_phone_room.mp4\n",
      "25__outside_talking_pan_laughing.mp4\n",
      "25__outside_talking_pan_laughing.mp4\n",
      "25__outside_talking_still_laughing.mp4\n",
      "25__outside_talking_still_laughing.mp4\n",
      "25__podium_speech_happy.mp4\n",
      "25__podium_speech_happy.mp4\n",
      "25__secret_conversation.mp4\n",
      "25__secret_conversation.mp4\n",
      "25__talking_against_wall.mp4\n",
      "25__talking_against_wall.mp4\n",
      "25__walking_down_street_outside_angry.mp4\n",
      "25__walking_down_street_outside_angry.mp4\n",
      "25__walking_outside_cafe_disgusted.mp4\n",
      "25__walking_outside_cafe_disgusted.mp4\n",
      "25__walk_down_hall_angry.mp4\n",
      "25__walk_down_hall_angry.mp4\n",
      "26__exit_phone_room.mp4\n",
      "26__exit_phone_room.mp4\n",
      "26__kitchen_pan.mp4\n",
      "26__kitchen_pan.mp4\n",
      "26__kitchen_still.mp4\n",
      "26__kitchen_still.mp4\n",
      "26__outside_talking_pan_laughing.mp4\n",
      "26__outside_talking_pan_laughing.mp4\n",
      "26__outside_talking_still_laughing.mp4\n",
      "26__outside_talking_still_laughing.mp4\n",
      "26__podium_speech_happy.mp4\n",
      "26__podium_speech_happy.mp4\n",
      "26__secret_conversation.mp4\n",
      "26__secret_conversation.mp4\n",
      "26__talking_against_wall.mp4\n",
      "26__talking_against_wall.mp4\n",
      "26__talking_angry_couch.mp4\n",
      "26__talking_angry_couch.mp4\n",
      "26__walking_down_street_outside_angry.mp4\n",
      "26__walking_down_street_outside_angry.mp4\n",
      "26__walking_outside_cafe_disgusted.mp4\n",
      "26__walking_outside_cafe_disgusted.mp4\n",
      "26__walk_down_hall_angry.mp4\n",
      "26__walk_down_hall_angry.mp4\n",
      "27__exit_phone_room.mp4\n",
      "27__exit_phone_room.mp4\n",
      "27__hugging_happy.mp4\n",
      "27__hugging_happy.mp4\n",
      "27__kitchen_pan.mp4\n",
      "27__kitchen_pan.mp4\n",
      "27__kitchen_still.mp4\n",
      "27__kitchen_still.mp4\n",
      "27__meeting_serious.mp4\n",
      "27__meeting_serious.mp4\n",
      "27__outside_talking_pan_laughing.mp4\n",
      "27__outside_talking_pan_laughing.mp4\n",
      "27__outside_talking_still_laughing.mp4\n",
      "27__outside_talking_still_laughing.mp4\n",
      "27__podium_speech_happy.mp4\n",
      "27__podium_speech_happy.mp4\n",
      "27__talking_against_wall.mp4\n",
      "27__talking_against_wall.mp4\n",
      "27__talking_angry_couch.mp4\n",
      "27__talking_angry_couch.mp4\n",
      "27__walking_and_outside_surprised.mp4\n",
      "27__walking_and_outside_surprised.mp4\n",
      "27__walking_down_indoor_hall_disgust.mp4\n",
      "27__walking_down_indoor_hall_disgust.mp4\n",
      "27__walking_down_street_outside_angry.mp4\n",
      "27__walking_down_street_outside_angry.mp4\n",
      "27__walking_outside_cafe_disgusted.mp4\n",
      "27__walking_outside_cafe_disgusted.mp4\n",
      "27__walk_down_hall_angry.mp4\n",
      "27__walk_down_hall_angry.mp4\n",
      "28__exit_phone_room.mp4\n",
      "28__exit_phone_room.mp4\n",
      "28__kitchen_pan.mp4\n",
      "28__kitchen_pan.mp4\n",
      "28__kitchen_still.mp4\n",
      "28__kitchen_still.mp4\n",
      "28__outside_talking_pan_laughing.mp4\n",
      "28__outside_talking_pan_laughing.mp4\n",
      "28__outside_talking_still_laughing.mp4\n",
      "28__outside_talking_still_laughing.mp4\n",
      "28__podium_speech_happy.mp4\n",
      "28__podium_speech_happy.mp4\n",
      "28__secret_conversation.mp4\n",
      "28__secret_conversation.mp4\n",
      "28__talking_angry_couch.mp4\n",
      "28__talking_angry_couch.mp4\n",
      "28__walking_down_street_outside_angry.mp4\n",
      "28__walking_down_street_outside_angry.mp4\n",
      "28__walking_outside_cafe_disgusted.mp4\n",
      "28__walking_outside_cafe_disgusted.mp4\n",
      "28__walk_down_hall_angry.mp4\n",
      "28__walk_down_hall_angry.mp4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_folder = \"../Forensic++ Dataset/FaceForensic/original_sequences\"  # Replace with your video folder path\n",
    "    main_output_folder = \"Dataset/Real\"  # Replace with your output folder path\n",
    "    reduced_output_dir = \"Reduced_Dataset/Real\"\n",
    "    found = 0\n",
    "    video_count = 303\n",
    "    for video_filename in os.listdir(video_folder):\n",
    "        if video_filename == \"23__walk_down_hall_angry.mp4\":\n",
    "            found = 1\n",
    "            print(\"found\")\n",
    "        if found == 1 and is_video(video_filename):\n",
    "            print(video_filename)\n",
    "            output_folder = os.path.join(main_output_folder, video_filename)\n",
    "            reduced_output = os.path.join(reduced_output_dir, video_filename)\n",
    "            video_path = os.path.join(video_folder, video_filename)\n",
    "            extract_frames_and_faces(video_path, output_folder, reduced_output, video_count)\n",
    "            print(video_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
