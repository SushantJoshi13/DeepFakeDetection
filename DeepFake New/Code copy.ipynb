{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sushant\\AppData\\Local\\Temp\\ipykernel_4688\\3943852633.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess image using Keras\n",
    "def load_and_preprocess_image(image_path, target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Function to extract image paths from a folder\n",
    "def extract_image_paths(root_folder, folder):\n",
    "    image_paths = []\n",
    "    for subdir, _, files in os.walk(os.path.join(root_folder, folder)):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(subdir, file)\n",
    "                image_paths.append(image_path)\n",
    "    return image_paths\n",
    "\n",
    "# Replace these paths with your actual dataset folder and subfolders\n",
    "root_folder_path = \"Reduced_Dataset\"\n",
    "real_folder = \"Real\"\n",
    "fake_folder = \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image paths for real and fake images\n",
    "real_image_paths = extract_image_paths(root_folder_path, real_folder)\n",
    "fake_image_paths = extract_image_paths(root_folder_path, fake_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels (0 for real, 1 for fake)\n",
    "real_labels = np.full(len(real_image_paths), \"Real\")\n",
    "fake_labels = np.full(len(fake_image_paths), \"Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Image_Path Nature\n",
      "21384  Reduced_Dataset\\Fake\\01_11__meeting_serious__F...   Fake\n",
      "21385  Reduced_Dataset\\Fake\\01_26__outside_talking_pa...   Fake\n",
      "21386  Reduced_Dataset\\Real\\14__walk_down_hall_angry....   Real\n",
      "21387  Reduced_Dataset\\Real\\03__hugging_happy.mp4\\fra...   Real\n",
      "21388  Reduced_Dataset\\Fake\\03_09__outside_talking_st...   Fake\n"
     ]
    }
   ],
   "source": [
    "# Combine real and fake data\n",
    "X = np.concatenate([real_image_paths, fake_image_paths], axis=0)\n",
    "y = np.concatenate([real_labels, fake_labels], axis=0)\n",
    "df = pd.DataFrame({'Image_Path': X, 'Nature': y})\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17112 validated image filenames belonging to 2 classes.\n",
      "Found 4277 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size = (224, 224)\n",
    "\n",
    "# Create an ImageDataGenerator for real and fake images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2)\n",
    "\n",
    "# Create a flow_from_dataframe generator for training\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Nature',\n",
    "    target_size=target_size,\n",
    "    batch_size=8,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Create a flow_from_dataframe generator for validation\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Nature',\n",
    "    target_size=target_size,\n",
    "    batch_size=8,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(images):\n",
    "    glcm_features = []\n",
    "    for img in images:\n",
    "        # Calculate GLCM\n",
    "        glcm = graycomatrix(img, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "        # Extract properties from GLCM\n",
    "        properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "        glcm_props = [graycoprops(glcm, prop).ravel()[0] for prop in properties]\n",
    "        glcm_features.append(glcm_props)\n",
    "    return np.array(glcm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resnet_features(images):\n",
    "    # Load pre-trained ResNet50 model\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False,input_shape=(224, 224, 3), pooling='avg')\n",
    "    # Preprocess images for ResNet50\n",
    "    preprocessed_images = tf.keras.applications.resnet50.preprocess_input(images)\n",
    "    # Extract features using ResNet50\n",
    "    features = base_model.predict(preprocessed_images)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_resnet, input_shape_glcm, num_classes):\n",
    "    # Define input layers for ResNet50 and GLCM features\n",
    "    input_resnet = Input(shape=input_shape_resnet)\n",
    "    input_glcm = Input(shape=input_shape_glcm)\n",
    "    \n",
    "    # Concatenate ResNet50 and GLCM features\n",
    "    combined_features = Concatenate()([input_resnet, input_glcm])\n",
    "    \n",
    "    # Add a dense layer for classification\n",
    "    dense_layer = Dense(64, activation='relu')(combined_features)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(dense_layer)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=[input_resnet, input_glcm], outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CheckPoint added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.0 GiB for an array with shape (21389, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(images)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Extract ResNet50 features\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m resnet_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_resnet_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract GLCM features\u001b[39;00m\n\u001b[0;32m     14\u001b[0m glcm_features \u001b[38;5;241m=\u001b[39m extract_glcm_features(images)\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mextract_resnet_features\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      5\u001b[0m preprocessed_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mresnet50\u001b[38;5;241m.\u001b[39mpreprocess_input(images)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract features using ResNet50\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:96\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m   value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.0 GiB for an array with shape (21389, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "# Load and preprocess images\n",
    "images = []\n",
    "for path in X:\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "images = np.array(images)\n",
    "\n",
    "# Extract ResNet50 features\n",
    "resnet_features = extract_resnet_features(images)\n",
    "\n",
    "# Extract GLCM features\n",
    "glcm_features = extract_glcm_features(images)\n",
    "\n",
    "# Define input shapes\n",
    "input_shape_resnet = resnet_features.shape[1:]\n",
    "input_shape_glcm = glcm_features.shape[1:]\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Create and compile model\n",
    "model = create_model(input_shape_resnet, input_shape_glcm, num_classes)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=patience, min_delta=min_delta, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "with tf.device('/GPU:0'):  # Ensure training is done on GPU\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,  # Increase the number of epochs\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "        class_weight=class_weights_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Save the model\n",
    "model.save('Resnet_GLCM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define paths to your data\n",
    "test_data_dir = \"Testing\"  # Replace with your testing data path\n",
    "\n",
    "# Define image dimensions (assuming you used these during training)\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Load your trained ResNet50 model\n",
    "model = load_model(\"trained_resnet_model_real_fake_Optimized.h5\")\n",
    "\n",
    "# Define data generators for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=8,  # Adjust batch size as needed\n",
    "    class_mode='binary'  # Adjust class mode based on your task (e.g., 'binary' for 2 classes)\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Additional analysis (optional)\n",
    "# predictions = model.predict(test_generator)\n",
    "# Analyze predictions based on your specific task (e.g., confusion matrix, visualization)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
